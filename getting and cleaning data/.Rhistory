pollutantmean("specdata","sulfate",1:10)
pollutantmean <-function(directory, pollutant, id=1:332){
my_data <- c()
filename <- paste("C:/Users/Ivan.Liuyanfeng/Desktop/Data_Mining_Work_Space/datasciencecoursera/",directory,"/",sep="")
for(i in id){
if (i <10){
i <- paste("00",i,sep="")
}else if(i<100){
i<-paste("0",i,sep="")
}
filename2 <- paste(filename, i,".csv",sep="")
my_data <- rbind(my_data,read.csv(filename2,header = TRUE))
}
print(colnames(my_data))
}
pollutantmean("specdata","sulfate",1:10)
pollutantmean <-function(directory, pollutant, id=1:332){
my_data <- c()
filename <- paste("C:/Users/Ivan.Liuyanfeng/Desktop/Data_Mining_Work_Space/datasciencecoursera/",directory,"/",sep="")
for(i in id){
if (i <10){
i <- paste("00",i,sep="")
}else if(i<100){
i<-paste("0",i,sep="")
}
filename2 <- paste(filename, i,".csv",sep="")
my_data <- rbind(my_data,read.csv(filename2,header = TRUE))
}
print(my_data$pollutant)
}
pollutantmean("specdata","sulfate",1:10)
pollutantmean <-function(directory, pollutant, id=1:332){
my_data <- c()
filename <- paste("C:/Users/Ivan.Liuyanfeng/Desktop/Data_Mining_Work_Space/datasciencecoursera/",directory,"/",sep="")
for(i in id){
if (i <10){
i <- paste("00",i,sep="")
}else if(i<100){
i<-paste("0",i,sep="")
}
filename2 <- paste(filename, i,".csv",sep="")
my_data <- rbind(my_data,read.csv(filename2,header = TRUE))
}
print(my_data[,pollutant])
}
pollutantmean("specdata","sulfate",1:10)
pollutantmean <-function(directory, pollutant, id=1:332){
my_data <- c()
filename <- paste("C:/Users/Ivan.Liuyanfeng/Desktop/Data_Mining_Work_Space/datasciencecoursera/",directory,"/",sep="")
for(i in id){
if (i <10){
i <- paste("00",i,sep="")
}else if(i<100){
i<-paste("0",i,sep="")
}
filename2 <- paste(filename, i,".csv",sep="")
my_data <- rbind(my_data,read.csv(filename2,header = TRUE))
}
my_mean <- mean(my_data[,pollutant],na.rm = TRUE)
print(my_mean)
}
pollutantmean("specdata","sulfate",1:10)
pollutantmean("specdata","nitrate",70:72)
pollutantmean("specdata","nitrate",23)
My first R Markdown File
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("week2quiz","6614a43b7641be7a6666")
myapp <- oauth_app("github","6614a43b7641be7a6666")
myapp <- oauth_app("github","6614a43b7641be7a6666")
myapp <- oauth_app("github","56b637a5baffac62cad9")
myapp <- oauth_app("github", "56b637a5baffac62cad9")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
?oauth_app
myapp <- oauth_app("week2quiz", "67926c344faef2ea1e88083564fb60df94109452")
myapp <- oauth_app("week2quiz", "67926c344faef2ea1e88083564fb60df94109452")
github_token <- oauth2.0_token(oauth_endpoints("week2quiz"), myapp)
library(httr)
# 1. Find OAuth settings for github:
#    http://developer.github.com/v3/oauth/
oauth_endpoints("github")
# 2. Register an application at https://github.com/settings/applications
#    Insert your values below - if secret is omitted, it will look it up in
#    the GITHUB_CONSUMER_SECRET environmental variable.
#
#    Use http://localhost:1410 as the callback url
myapp <- oauth_app("github", "56b637a5baffac62cad9")
# 3. Get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
# 4. Use API
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
content(req)
# OR:
req <- with_config(gtoken, GET("https://api.github.com/rate_limit"))
stop_for_status(req)
content(req)
install.packages(c("Formula", "gplots", "gtools", "markdown", "mboost", "mime", "multcomp", "mvoutlier", "party", "randomForest", "rattle", "Rcpp", "RCurl", "rgl", "RGtk2", "rjson", "sandwich", "sem", "swirl", "tm", "vcd", "wordcloud", "XLConnect", "xlsx"))
setwd("C:\Users\Ivan.Liuyanfeng\Desktop\Data_Mining_Work_Space\datasciencecoursera\getting and cleaning data")
setwd("C:/Users/Ivan.Liuyanfeng/Desktop/Data_Mining_Work_Space/datasciencecoursera/getting and cleaning data")
acs.url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
acs.zip <- basename(acs.url)
acs.zip
source(week2quiz.R)
source("week2quiz.R")
readacs
readacs()
setwd("C:/Users/Ivan.Liuyanfeng/Desktop/Data_Mining_Work_Space/datasciencecoursera/getting and cleaning data")
acs.url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
acs.filename <- basename(acs.url)
if (!(file.exists(acs.filename)))
download.file(acs.url, destfile=acs.filename,method="curl")
acs.url <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
acs.filename <- basename(acs.url)
if (!(file.exists(acs.filename)))
download.file(acs.url, destfile=acs.filename,method="curl")
setwd("C:/Users/Ivan.Liuyanfeng/Desktop/Data_Mining_Work_Space/datasciencecoursera/getting and cleaning data/)
acs.url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
acs.filename <- basename(acs.url)
if (!(file.exists(acs.filename)))
download.file(acs.url, destfile=acs.filename,method="curl")
acs <- read.csv(acs.url)
head(acs)
source("week2quiz.R")
source("week2quiz.R")
readacs()
require(sqldf)
install.packages("sqldf")
question1 <- sqldf("select pwgtp1 from acs where AGEP <50")
require(sqldf)
question1 <- sqldf("select pwgtp1 from acs where AGEP <50")
question1
print("Data for the probability weights pwgtp1 with ages less than 50:")
head(question1)
unique(acs$AGEP)
question2.1<-unique(acs$AGEP)
head(question2.1)
question2.2 <- sqldf("select distinct AGEP from acs")
head(c(question2.1,question2.2))
question2.1<-unique(acs$AGEP)
question2.2 <- sqldf("select distinct AGEP from acs")
head(question2.1)
head(question2.2)
?nchar
?url
con <- url("http://biostat.jhsph.edu/~jleek/contact.html")
question3 <- readLines(con)
question3
?apply
lines<-c(10,20,30,100)
lapply <- (question3[lines,],nchar)
question3[lines,]
question3[,lines]
question3[lines]
question3[2]
lines<-c(10,20,30,100)
question3.2 <- lapply(question3[lines],nchar)
question3.2
data.url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
q5.data<- read.table(file = data.url)
setwd("C:/Users/Ivan.Liuyanfeng/Desktop/Data_Mining_Work_Space/datasciencecoursera/getting and cleaning data/")
uscom.url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
uscom.file <- basename(uscom.url)
uscom.file
if(!(file.exists(uscom.file))){
download.file(url = uscom.url,destfile = uscom.file,method = "curl")
}
install.packages("curl")
if(!(file.exists(uscom.file))){
download.file(url = uscom.url,destfile = uscom.file,method = "auto")
}
uscom.data <- read.csv(uscom.file)
head(uscom.data)
source("week3quiz.R")
week3quiz()
head(agrucyktyrekKigucak)
head(agriculturelLogical)
setwd("C:/Users/Ivan.Liuyanfeng/Desktop/Data_Mining_Work_Space/datasciencecoursera/getting and cleaning data/")
# Question 1
uscom.url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
uscom.file <- basename(uscom.url)
if(!(file.exists(uscom.file))){
download.file(url = uscom.url,destfile = uscom.file,method = "auto")
}
uscom.data <- read.csv(uscom.file)
attach(uscom.data)
agriculturelLogical <- uscom.data[(ACR==3 & AGS==6),]
head(agriculturelLogical)
head(uscom.data)
agriculturelLogical <- uscom.data[,(ACR==3 & AGS==6)]
return(agriculturelLogical)
agriculturelLogical <- uscom.data[(ACR==3 & AGS==6),]
return(agriculturelLogical)
head(uscom.data)
uscom.data[(ACR==3),]
class(uscom.data)
uscom.data[which(ACR==3),]
attach(uscom.data)
agriculturelLogical <- uscom.data[which(ACR==3 & AGS==6),]
return(agriculturelLogical)
source("week3quiz.R")
week3quiz()
week3quiz()
source("week3quiz.R")
week3quiz()
install.packages("jpeg")
library(jpeg)
?jpeg
a <- jpeg(filename = "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg")
a <- readJPEG("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg", native=T)
a <- readJPEG("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg", native=TRUE)
library(jpeg)
img.url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
img.file <- basename(img.url)
if(!(file.exists(img.file))){
download.file(img.url,destfile=img.file,method="auto")
}
img.data <- readJPEG(img.file,native = TRUE)
img.data <- readJPEG(img.file,native = TRUE)
head(img.dat)
head(img.data)
img.data
img.data <- readJPEG(img.file,native = TRUE)
quantile.per <- c(.3,.8)
question2 <- quantile(img.data, probs = quantile.per)
question2
GDP.url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
GDP.file <- basename(GDP.url)
if(!(file.exists(GDP.file))){
download.file(GDP.url, destfile = GDP.file,method = "auto")
}
GDP.data <- read.csv(GDP.file)
EDU.url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
EDU.file <- basename(EDU.url)
if(!(file.exists(EDU.file))){
download.file(EDU.url, destfile = EDU.file,method = "auto")
}
EDU.data <- read.csv(EDU.file)
head(GDP.data)
head(EDU.data)
str(EDU.data)
str(GDP.data)
GDP.data$x
summar(GDP.data)
summary(GDP.data)
GDP.data[1,]
GDP.data[,1]
a <- GDP.data$x
a
colnames(GDP.data[,1])
colnames(GDP.data)
a <- GDP.data$X
a
a <- GDP.data$X %in% EDU.data$CountryCode
a
table(a)
a <- EDU.data$CountryCode %in% GDP.data$X
table(a)
b <- GDP.data$X %in% EDU.data$CountryCode
table(c(a,b))
c <- a==b
table(a,b)
name(GDP.data)
names(GDP.data)
names(EDU.data)
merged.data <- merge(GDP.data,EDU.data, by.x="X", by.y="CountryCode",all=TRUE)
merged.data
head(merged.data)
table(merged.data)
table(merged.data$[,1])
table(merged.data$[1,])
summary(merged.data)
summary(merged.data[,1])
summary(merged.data[,1])
table(merged.data[,1])
table(merged.data[,1], useNA="ifany")
sum(!is.na(merged.data[,1]))
sum(is.na(merged.data[,1]))
colSums(is.na(merged.data))
merged.data <- merge(GDP.data,EDU.data, by.x="X", by.y="CountryCode")
colSums(is.na(merged.data))
sum(is.na(merged.data[,1]))
sum(!is.na(merged.data[,1]))
?merge
library(plyr)
sorted.data <- arrange(merged.data, desc(X))
sorted.data <- arrange(merged.data, desc(merged.data[,2]))
sorted.data[,1]
sorted.data[13,1]
sorted.data[13]
sorted.data[13,]
sorted.data <- arrange(GDP.data, desc(GDP.data[,2]))
sorted.data[13,]
sorted.data <- arrange(GDP.data, desc(GDP.data[,2]))
sorted.data[,2]
sorted.data <- arrange(merged.data, desc(as.numeric(merged.data[,2])))
sorted.data[13,]
sorted.data <- arrange(merged.data, desc(as.numeric(merged.data[,2])))
sorted.data[,2]
as.numeric(sorted.data[,2])
merged.data[,2]
as.numeric(merged.data[,2])
merged.data[,2]<-as.numeric(merged.data[,2])
sorted.data <- arrange(merged.data, desc(merged.data[,2]))
sorted.data[13,]
sorted.data[,2]
sorted.data[13,c(1,2)]
GDP.url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
GDP.file <- basename(GDP.url)
if(!(file.exists(GDP.file))){
download.file(GDP.url, destfile = GDP.file,method = "auto")
}
GDP.data <- read.csv(GDP.file)
EDU.url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
EDU.file <- basename(EDU.url)
if(!(file.exists(EDU.file))){
download.file(EDU.url, destfile = EDU.file,method = "auto")
}
EDU.data <- read.csv(EDU.file)
#head(GDP.data)
#head(EDU.data)
merged.data <- merge(GDP.data,EDU.data, by.x=GDP.data$X, by.y=EDU.data$CountryCode)
library(plyr)
merged.data <- merge(GDP.data,EDU.data, by.x=GDP.data$X, by.y=EDU.data$CountryCode)
GDP.data$X
EDU.data$CountryCode
merged.data <- merge(GDP.data,EDU.data, by.x="X", by.y="CountryCode" )
merged.data
merged.data <- merge(GDP.data,EDU.data, by.x="X", by.y="CountryCode",all=T )
q3.1 <- sum(!is.na(merged.data[,1]))
q3.1
merged.data[,1]
table(merged.data[,1])
merged.data <- merge(GDP.data,EDU.data, by.x="X", by.y="CountryCode",all.x=T )
table(merged.data[,1])
merged.data[,1]
merged.data <- merge(GDP.data,EDU.data, by.x="X", by.y="CountryCode",all.y=T )
merged.data[,1]
merged.data <- merge(GDP.data,EDU.data, by.x="X", by.y="CountryCode" )
merged.data[,1]
merged.data[,c(1,2)]
q.data <- merged.data[,c(1,2)]
s.data <- q.data[sort(q.data[,2]),]
s.data
s.data <- q.data[sort(as.numeric(q.data[,2])),]
s.data
as.numeric(q.data[,2])
sort(as.numeric(q.data[,2]))
b <- sort(as.numeric(q.data[,2]),decreasing = TRUE,na.last = TRUE)
b
b[13]
c <- q.data[which(q.data[,2]==b[13]),]
c
c <- q.data[which(as.numeric(q.data[,2])==b[13]),]
c
q.data
merged.data
merged.data[,2]
as.numeric(merged.data[,2])
a <- as.numeric(merged.data[,2])
a
b <- sort(a)
b
b <- arrange(a)
a <- as.data.frame(a)
b <- arrange(a)
b <- sort(a)
merged.data <- merge(GDP.data,EDU.data, by.x="X", by.y="CountryCode",all=T )
str(merged.data)
summary(merged.data)
?cut
merged.data$GDP_group<- cut(merged.data[,2], breaks=quantile(merged.data[,2]))
table(merged.data$GDP_group)
c <- as.numeric(merged.data[,2])
merged.data$GDP_group<- cut(merged.data[,2], breaks=quantile(c))
table(merged.data$GDP_group)
c <- as.numeric(merged.data[,2])
merged.data$GDP_group<- cut(c, breaks=quantile(c))
table(merged.data$GDP_group)
merged.data <- merge(GDP.data,EDU.data, by.x="X", by.y="CountryCode" )
c <- as.numeric(merged.data[,2])
merged.data$GDP_group<- cut(c, breaks=quantile(c))
table(merged.data$GDP_group)
merged.data$GDP_group<- cut(c, breaks=quantile(.2,.4,.6,.8,1))
table(merged.data$GDP_group)
merged.data$GDP_group<- cut(c, breaks=quantile(c(.2,.4,.6,.8,1)))
table(merged.data$GDP_group)
merged.data$GDP_group<- cut(c, breaks=quantile(c, probs = c(.2,.4,.6,.8,1)))
table(merged.data$GDP_group)
merged.data$GDP_group<- cut(c, breaks=quantile(c, probs = c(0,0.2,0.4,0.6,0.8)))
table(merged.data$GDP_group)
merged.data$GDP_group<- cut(c, breaks=quantile(c, probs = c(0,0.2,0.4,0.6,0.8,1.0)))
table(merged.data$GDP_group)
str(merged.data)
table(merged.data$GDP_group,merged.data$Income.Group)
merged.data$GDP_group<- cut(c, breaks=quantile(c, probs = c(0.2,0.4,0.6,0.8,1.0)))
table(merged.data$GDP_group,merged.data$Income.Group)
GDP.url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
GDP.file <- basename(GDP.url)
if(!(file.exists(GDP.file))){
download.file(GDP.url, destfile = GDP.file,method = "auto")
}
GDP.data <- read.csv(GDP.file)
EDU.url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
EDU.file <- basename(EDU.url)
if(!(file.exists(EDU.file))){
download.file(EDU.url, destfile = EDU.file,method = "auto")
}
EDU.data <- read.csv(EDU.file)
GDP.data
GDP.data <- read.csv(GDP.file, skip = 11, nrow=471)
GDP.data
GDP.data <- read.csv(GDP.file, skip = 11, nrow=471)
GDP.data
head(GDP.data)
GDP.data <- read.csv(GDP.file, skip = 11, nrow=471,ncol=c(1,2,4,5))
GDP.url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
GDP.file <- basename(GDP.url)
if(!(file.exists(GDP.file))){
download.file(GDP.url, destfile = GDP.file,method = "auto")
}
GDP.data <- read.csv(GDP.file, skip = 11, nrow=471,ncol=c(1,2,4,5))
EDU.url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
EDU.file <- basename(EDU.url)
if(!(file.exists(EDU.file))){
download.file(EDU.url, destfile = EDU.file,method = "auto")
}
EDU.data <- read.csv(EDU.file)
#head(GDP.data)
#head(EDU.data)
merged.data <- merge(GDP.data,EDU.data, by.x="X", by.y="CountryCode" )
q3.1 <- sum(!is.na(merged.data[,1]))
table(merged.data[,1])
library(plyr)
merged.data[,2]<-as.numeric(merged.data[,2])
sorted.data <- arrange(merged.data, desc(merged.data[,2]))
sorted.data[13,]
GDP.data <- read.csv(GDP.file, skip = 11, nrow=471)
EDU.url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
EDU.file <- basename(EDU.url)
if(!(file.exists(EDU.file))){
download.file(EDU.url, destfile = EDU.file,method = "auto")
}
EDU.data <- read.csv(EDU.file)
#head(GDP.data)
#head(EDU.data)
merged.data <- merge(GDP.data,EDU.data, by.x="X", by.y="CountryCode" )
q3.1 <- sum(!is.na(merged.data[,1]))
table(merged.data[,1])
library(plyr)
merged.data[,2]<-as.numeric(merged.data[,2])
sorted.data <- arrange(merged.data, desc(merged.data[,2]))
sorted.data[13,]
merged.data <- merge(GDP.data,EDU.data, by.x="X", by.y="CountryCode" )
merged.data
GDP.url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
GDP.file <- basename(GDP.url)
if(!(file.exists(GDP.file))){
download.file(GDP.url, destfile = GDP.file,method = "auto")
}
GDP.data <- read.csv(GDP.file, skip = 11, nrow=471)
EDU.url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
EDU.file <- basename(EDU.url)
if(!(file.exists(EDU.file))){
download.file(EDU.url, destfile = EDU.file,method = "auto")
}
EDU.data <- read.csv(EDU.file)
merged.data <- merge(GDP.data,EDU.data, by.x="X", by.y="CountryCode" )
merged.data[,2]<-as.numeric(merged.data[,2])
sorted.data <- arrange(merged.data, desc(merged.data[,2]))
sorted.data[13,]
GDP.url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
GDP.file <- basename(GDP.url)
if(!(file.exists(GDP.file))){
download.file(GDP.url, destfile = GDP.file,method = "auto")
}
GDP.data <- read.csv(GDP.file, skip = 11, nrow=471)
EDU.url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
EDU.file <- basename(EDU.url)
if(!(file.exists(EDU.file))){
download.file(EDU.url, destfile = EDU.file,method = "auto")
}
EDU.data <- read.csv(EDU.file)
#head(GDP.data)
#head(EDU.data)
merged.data <- merge(GDP.data,EDU.data, by.x="X", by.y="CountryCode" )
merged.data
GDP.data
head(GDP.data)
EDU.data <- read.csv(EDU.file)
head(EDU.data)
merged.data <- merge(GDP.data,EDU.data, by.x="X", by.y="CountryCode" )
head(merged.data)
GDP.data <- read.csv(GDP.file)
merged.data <- merge(GDP.data,EDU.data, by.x="X", by.y="CountryCode" )
head(merged.data)
q3.1 <- sum(!is.na(merged.data[,1]))
table(merged.data[,1])
head(merged.data)
library(plyr)
merged.data[,2]<-as.numeric(merged.data[,2])
sorted.data <- arrange(merged.data, desc(merged.data[,2]))
sorted.data[13,]
sorted.data[,2]
merged.data[,2]
sort(merged.data[,2])
merged.data <- merge(GDP.data,EDU.data, by.x="X", by.y="CountryCode" )
merged.data[,2]
table(merged.data[,2])
merged.data[,2]
